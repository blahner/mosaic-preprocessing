{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize stimulus embeddings from multiple datasets to examine their diversity/clustering and test/train differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getenv('PYTHONPATH')) \n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "#local\n",
    "from src.utils.dataset import FMRIDataset\n",
    "from src.utils.transforms import SelectROIs\n",
    "from src.utils.helpers import FilterDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housekeeping\n",
    "cols = ['fmri','stimulus_filename', 'subject_id', 'dataset_id']\n",
    "all_data = {col: [] for col in cols}\n",
    "root = os.path.join(os.getenv(\"DATASETS_ROOT\", \"/default/path/to/datasets\"), \"MOSAIC\")\n",
    "project_root = os.path.join(os.getenv(\"PROJECT_ROOT\"))\n",
    "rois = [f\"GlasserGroup_{x}\" for x in range(1,6)]\n",
    "config = {\"fmri\": {\"dataset_include\": ['GOD','deeprecon'],\n",
    "                   \"subject_include\": None,\n",
    "                   \"use_noiseceiling\": True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a train/test json to identify filenames\n",
    "    #load train and test jsons\n",
    "with open(os.path.join(root, 'train_naturalistic.json'), 'r') as f:\n",
    "    train_val_all = json.load(f)\n",
    "with open(os.path.join(root, 'test_naturalistic.json'), 'r') as f:\n",
    "    test_all = json.load(f)\n",
    "dataset_preprocessing = FilterDataset(config)\n",
    "train_val = dataset_preprocessing.filter_splits(train_val_all)\n",
    "test = dataset_preprocessing.filter_splits(test_all)\n",
    "subjectID_mapping = dataset_preprocessing.subjectID_map()\n",
    "idx_to_subjectID = {v:k for k,v in subjectID_mapping.items()}\n",
    "\n",
    "shuffled_indices_train_val = np.random.permutation(len(train_val))\n",
    "train_val = [train_val[i] for i in shuffled_indices_train_val]\n",
    "\n",
    "shuffled_indices_test= np.random.permutation(len(test))\n",
    "test = [test[i] for i in shuffled_indices_test]\n",
    "n = len(test)\n",
    "#n=200\n",
    "#train_val = train_val[:n] #just for debugging\n",
    "#test = test[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_selection = SelectROIs(selected_rois=rois)\n",
    "fmri_tsfm = v2.Compose([roi_selection])\n",
    "dataset = FMRIDataset(test, config['fmri']['use_noiseceiling'], 'average', subjectID_mapping=subjectID_mapping, fmri_transforms=fmri_tsfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['fmri','stimulus_filename', 'subject_id', 'dataset_id']\n",
    "all_data = {col: [] for col in cols}\n",
    "\n",
    "for idx in tqdm(range(len(dataset)), total=len(dataset), desc=\"Gathering responses from dataset\"):\n",
    "    sample = dataset.get_all_responses(idx)\n",
    "    stimulus_filename = sample['stimulus_filename']\n",
    "    #loop over individual responses for that stimulus\n",
    "    for s in range(len(sample['fmri'])):\n",
    "        fmri = sample['fmri'][s]\n",
    "        subjectID = sample['subjectID'][s]\n",
    "\n",
    "        if config['fmri']['use_noiseceiling']:\n",
    "            noiseceiling = sample['noiseceiling'][s]\n",
    "            all_data['fmri'].append(fmri*noiseceiling)\n",
    "        else:\n",
    "            all_data['fmri'].append(fmri)\n",
    "        all_data['stimulus_filename'].append(stimulus_filename)\n",
    "        all_data['subject_id'].append(idx_to_subjectID[subjectID])\n",
    "        all_data['dataset_id'].append(idx_to_subjectID[subjectID].split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_data)\n",
    "X = np.vstack(df['fmri'].to_numpy())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scaling...\")\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "# Perform UMAP dimensionality reduction\n",
    "print(\"UMAP reduction...\")\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "X_umap = reducer.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add UMAP projections to DataFrame\n",
    "df['X'] = X_umap[:, 0]\n",
    "df['Y'] = X_umap[:, 1]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df, x='X', y='Y', hue='dataset_id', palette='tab10', s=10, alpha=0.6)\n",
    "#\n",
    "plt.title('UMAP Projection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_subjects = df['subject_id'].unique()\n",
    "palette = sns.color_palette('tab10', len(unique_subjects))\n",
    "color_map = dict(zip(unique_subjects, palette))\n",
    "# Assuming 'df' is your DataFrame, 'X_tsne' contains the t-SNE results, and you have 'stimulus_filename' in df.\n",
    "\n",
    "# Set up the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Get the center coordinates of the plot\n",
    "x_center = (np.max(X_umap[:, 0]) + np.min(X_umap[:, 0])) / 2\n",
    "y_center = (np.max(X_umap[:, 1]) + np.min(X_umap[:, 1])) / 2\n",
    "stretch = np.floor(700 / (np.abs(np.max(X_umap.ravel())) + np.abs(np.min(X_umap.ravel()))))\n",
    "print(\"stretch:\", stretch)\n",
    "scaler = 0.02 #adjust according to the resolution of the image and number of images you are plotting\n",
    "\n",
    "# Track minimum and maximum x and y for setting axis limits later\n",
    "min_x, max_x = np.inf, -np.inf\n",
    "min_y, max_y = np.inf, -np.inf\n",
    "print(\"looping over dataframe rows...\")\n",
    "for idx, row in df.iterrows():\n",
    "    img_path = os.path.join(root, \"stimuli\", \"stimuli_compressed_quality-95_size-224\", row['stimulus_filename'])\n",
    "    label = row['subject_id']\n",
    "    color = color_map[label]  # Get the color for the dataset_id\n",
    "\n",
    "    x = row['X']\n",
    "    y = row['Y']\n",
    "    x_new = x_center + x*stretch\n",
    "    y_new = y_center + y*stretch\n",
    "    # plot middle frame \n",
    "    img = np.array(Image.open(os.path.join(img_path))).astype(np.float64) /255 #.astype('uint8')\n",
    "\n",
    "    # Update min/max coordinates to accommodate the image extent\n",
    "    min_x = min(min_x, x_new)\n",
    "    max_x = max(max_x, x_new + scaler * img.shape[1])\n",
    "    min_y = min(min_y, y_new)\n",
    "    max_y = max(max_y, y_new + scaler * img.shape[0])\n",
    "\n",
    "    # Add a border using plt.Rectangle with the subject_id's color\n",
    "    rect = plt.Rectangle((x_new, y_new), scaler * img.shape[1], scaler * img.shape[0],\n",
    "                         linewidth=1, edgecolor=color, facecolor='none', zorder=1)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    ax.imshow(img, extent=[x_new, x_new+scaler*img.shape[1], y_new, y_new+scaler*img.shape[0]], zorder=2)\n",
    "\n",
    "padding = scaler * 80  # Adjust based on image size\n",
    "ax.set_xlim(min_x - padding, max_x + padding)\n",
    "ax.set_ylim(min_y - padding, max_y + padding)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Create legend patches for each dataset_id\n",
    "legend_patches = [Patch(color=color_map[subject], label=subject) for subject in unique_subjects]\n",
    "# Add the legend outside the plot\n",
    "plt.legend(handles=legend_patches, title=\"Subject ID\", bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "# Adjust layout to make space for the legend\n",
    "plt.subplots_adjust(right=0.8)\n",
    "\n",
    "print(\"saving plot...\")\n",
    "plot_fname = f\"ROIs-{('-').join(rois)}_subjects-{('-').join(dataset_preprocessing.subjects_to_include)}_usenoiseceiling-{config['fmri']['use_noiseceiling']}_n-{n}_umap.png\"\n",
    "save_root = os.path.join(project_root, \"src\", \"fmriDatasetPreparation\", \"visualizations\", \"fmri_embedding_tsne\")\n",
    "if not os.path.exists(save_root):\n",
    "    os.makedirs(save_root)\n",
    "plt.savefig(os.path.join(save_root, plot_fname), dpi=300)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as json for viewing in webpage\n",
    "df.drop('fmri', axis=1, inplace=True)\n",
    "json_filename = f\"ROIs-{('-').join(rois)}_n-{n}_umap.json\"\n",
    "df.to_json(os.path.join(project_root, \"assets\", json_filename), orient='records', lines=False)\n",
    "df.to_json(os.path.join(\"/data/vision/oliva/blahner/projects/BrainEmbedder/data/umap\", json_filename), orient='records', lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as json for viewing in webpage\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SheenBrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
