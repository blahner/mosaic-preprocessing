{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append(os.getenv('PYTHONPATH')) \n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import MDS\n",
    "from PIL import Image\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "from torchvision.transforms import v2\n",
    "from pathlib import Path\n",
    "\n",
    "#local\n",
    "from src.utils.helpers import FilterDataset\n",
    "from src.utils.dataset import FMRIDataset\n",
    "from src.utils.transforms import SelectROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mds(utv, pos=None, n_jobs=1, n_components=2):\n",
    "    #this function copied from NSD code\n",
    "    \"\"\" pos = mds(utv)\n",
    "\n",
    "    mds computes the multi-dimensional scaling solution on a \n",
    "    two dimensional plane, for a representational dissimilarity matrix.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        utv (array): 1D upper (or lower) triangular part of an RDM\n",
    "\n",
    "        pos (array, optional): set of 2D coordinates to initialise the MDS\n",
    "                            with. Defaults to None.\n",
    "\n",
    "        n_jobs (int, optional): number of cores to distribute to.\n",
    "                            Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        [array]: 2D aray of x and y coordinates.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    rdm = squareform(utv)\n",
    "    seed = np.random.RandomState(seed=3)\n",
    "    mds = MDS(\n",
    "        n_components=n_components,\n",
    "        max_iter=100,\n",
    "        random_state=seed,\n",
    "        dissimilarity=\"precomputed\",\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    pos = mds.fit_transform(rdm, init=pos)\n",
    "\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housekeeping\n",
    "ncomponents = 2\n",
    "perplexity=20\n",
    "save_flag = False\n",
    "trialselection='all' #'average'\n",
    "root = os.path.join(os.getenv(\"DATASETS_ROOT\", \"/default/path/to/datasets\"), \"MOSAIC\")\n",
    "project_root = os.path.join(os.getenv(\"PROJECT_ROOT\"))\n",
    "print(f\"root: {root}\")\n",
    "print(f\"project root: {project_root}\")\n",
    "config = {\"fmri\": {\"dataset_include\": ['GOD', 'deeprecon'],\n",
    "                   \"subject_include\": None,\n",
    "                   \"use_noiseceiling\": True}}\n",
    "n = 1 #'avg' #or n=1, only matters if 'use_noiseceiling' is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a train/test json to identify filenames\n",
    "    #load train and test jsons\n",
    "with open(os.path.join(root, 'train_naturalistic.json'), 'r') as f:\n",
    "    train_all = json.load(f)\n",
    "with open(os.path.join(root, 'test_naturalistic.json'), 'r') as f:\n",
    "    test_all = json.load(f)\n",
    "dataset_preprocessing = FilterDataset(config['fmri']['subject_include'],\n",
    "                                    config['fmri']['dataset_include'],\n",
    "                                    config['fmri']['use_noiseceiling'])\n",
    "#dataset_preprocessing = FilterDataset(['sub-01_deeprecon', 'sub-01_GOD'],\n",
    "#                                    None,\n",
    "#                                    config['fmri']['use_noiseceiling'])\n",
    "train, subjectID_mapping_train = dataset_preprocessing.filter_splits(train_all)\n",
    "test, subjectID_mapping_test = dataset_preprocessing.filter_splits(test_all)\n",
    "all_subjects_dict = {**subjectID_mapping_train, **subjectID_mapping_test}\n",
    "all_subjects = list(all_subjects_dict.keys())\n",
    "\n",
    "shuffled_indices_train = np.random.permutation(len(train))\n",
    "train = [train[i] for i in shuffled_indices_train]\n",
    "\n",
    "shuffled_indices_test= np.random.permutation(len(test))\n",
    "test = [test[i] for i in shuffled_indices_test]\n",
    "n = len(test)\n",
    "#n=200\n",
    "#train_val = train_val[:n] #just for debugging\n",
    "#test = test[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sets = ['train_naturalistic', 'test_naturalistic']\n",
    "stimuli_list = {'train_naturalistic': [Path(list(stim.keys())[0]).stem for stim in train],\n",
    "                'test_naturalistic': [Path(list(stim.keys())[0]).stem for stim in test]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = [\"GlasserGroup_1\", \"GlasserGroup_2\", \"GlasserGroup_3\",\"GlasserGroup_4\", \"GlasserGroup_5\"] #[\"LO1\",\"LO2\"] #[\"V1\"]\n",
    "ROI_selection = SelectROIs(selected_rois = rois)\n",
    "fmri_tsfm = None #v2.Compose([ToTensorfMRI(dtype='float32')])\n",
    "dataset = FMRIDataset(test, ROI_selection, config['fmri']['use_noiseceiling'], trialselection, fmri_transforms=fmri_tsfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['fmri','stimulus_filename', 'subject_id', 'dataset_id']\n",
    "all_data = {eval_set: {col: [] for col in cols} for eval_set in eval_sets}\n",
    "phase = 'test'\n",
    "n='avg'\n",
    "for subjectID in all_subjects: \n",
    "    sample = dataset.load_responses_block_hdf5(subjectID, verbose=True)\n",
    "    stimuli = sample['stimulus_filename']\n",
    "    for idx, stim in enumerate(stimuli):\n",
    "        fmri = sample['fmri'][idx,:]\n",
    "        subject_stim = f\"{subjectID}_stimulus-{stim}\"\n",
    "        for eval_set in eval_sets:\n",
    "            if subject_stim in stimuli_list[eval_set]:\n",
    "                if config['fmri']['use_noiseceiling']:\n",
    "                    noiseceiling = sample['noiseceiling'][f\"{subjectID}_phase-{phase}_n-{n}\"]\n",
    "                    all_data[eval_set]['fmri'].append(fmri*noiseceiling)\n",
    "                else:\n",
    "                    all_data[eval_set]['fmri'].append(fmri)\n",
    "                all_data[eval_set]['stimulus_filename'].append(stim)\n",
    "                all_data[eval_set]['subject_id'].append(subjectID)\n",
    "                all_data[eval_set]['dataset_id'].append(subjectID.split('_')[-1])\n",
    "                continue #no need to check other eval sets. Note that some stimuli got removed from the filtering so are not part of any eval set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.vstack(all_data['train_naturalistic']['fmri'])\n",
    "test_data = np.vstack(all_data['test_naturalistic']['fmri'])\n",
    "print(np.vstack(train_data).shape)\n",
    "print(np.vstack(test_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute ROI RDM\n",
    "rdm_flat = pdist(test_data, metric='correlation')\n",
    "rdm = squareform(rdm_flat)\n",
    "print(rdm.shape)\n",
    "plt.imshow(rdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#compute MDS\n",
    "Y_mds = mds(squareform(rdm), n_components=ncomponents)\n",
    "tsne = TSNE(n_components=ncomponents, metric='precomputed', init=Y_mds, random_state=42, perplexity=perplexity, n_jobs=4)\n",
    "X_tsne = tsne.fit_transform(rdm)\n",
    "print(\"divergence: \", tsne.kl_divergence_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_flag = True\n",
    "df = pd.DataFrame(all_data['test_naturalistic'])\n",
    "X = np.vstack(df['fmri'].to_numpy())\n",
    "print(X.shape)\n",
    "df['X'] = X_tsne[:, 0]\n",
    "df['Y'] = X_tsne[:, 1]\n",
    "\n",
    "unique_subjects = df['subject_id'].unique()\n",
    "unique_subjects = sorted(unique_subjects, key=lambda x: (x.split('_')[1], x.split('_')[0]))\n",
    "palette = [sns.color_palette('tab10')[0], sns.color_palette('tab10')[2], sns.color_palette('tab10')[3], sns.color_palette('tab10')[4], sns.color_palette('tab10')[5], sns.color_palette('tab10')[1], sns.color_palette('tab10')[6], sns.color_palette('tab10')[7]]\n",
    "#palette =  [sns.color_palette('tab10')[0], sns.color_palette('tab10')[1]] #sns.color_palette('tab10', len(unique_subjects))[::-1]\n",
    "color_map = dict(zip(unique_subjects, palette))\n",
    "# Assuming 'df' is your DataFrame, 'X_tsne' contains the t-SNE results, and you have 'stimulus_filename' in df.\n",
    "\n",
    "# Set up the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Get the center coordinates of the plot\n",
    "x_center = (np.max(X_tsne[:, 0]) + np.min(X_tsne[:, 0])) / 2\n",
    "y_center = (np.max(X_tsne[:, 1]) + np.min(X_tsne[:, 1])) / 2\n",
    "stretch = np.floor(700 / (np.abs(np.max(X_tsne.ravel())) + np.abs(np.min(X_tsne.ravel()))))\n",
    "print(\"stretch:\", stretch)\n",
    "scaler = 0.02 #adjust according to the resolution of the image and number of images you are plotting\n",
    "\n",
    "# Track minimum and maximum x and y for setting axis limits later\n",
    "min_x, max_x = np.inf, -np.inf\n",
    "min_y, max_y = np.inf, -np.inf\n",
    "print(\"looping over dataframe rows...\")\n",
    "for idx, row in df.iterrows():\n",
    "    img_path = os.path.join(root, \"stimuli\", \"stimuli_compressed_quality-95_size-224\", f\"{row['stimulus_filename']}.JPEG\")\n",
    "    label = row['subject_id']\n",
    "    color = color_map[label]  # Get the color for the dataset_id\n",
    "\n",
    "    x = row['X']\n",
    "    y = row['Y']\n",
    "    x_new = x_center + x*stretch\n",
    "    y_new = y_center + y*stretch\n",
    "    # plot middle frame \n",
    "    img = np.array(Image.open(os.path.join(img_path))).astype(np.float64) /255 #.astype('uint8')\n",
    "\n",
    "    # Update min/max coordinates to accommodate the image extent\n",
    "    min_x = min(min_x, x_new)\n",
    "    max_x = max(max_x, x_new + scaler * img.shape[1])\n",
    "    min_y = min(min_y, y_new)\n",
    "    max_y = max(max_y, y_new + scaler * img.shape[0])\n",
    "\n",
    "    # Add a border using plt.Rectangle with the subject_id's color\n",
    "    rect = plt.Rectangle((x_new, y_new), scaler * img.shape[1], scaler * img.shape[0],\n",
    "                         linewidth=3, edgecolor=color, facecolor='none', zorder=1)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    ax.imshow(img, extent=[x_new, x_new+scaler*img.shape[1], y_new, y_new+scaler*img.shape[0]], zorder=2)\n",
    "\n",
    "padding = scaler * 80  # Adjust based on image size\n",
    "ax.set_xlim(min_x - padding, max_x + padding)\n",
    "ax.set_ylim(min_y - padding, max_y + padding)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Create legend patches for each dataset_id\n",
    "legend_patches = [Patch(color=color_map[subject], label=subject) for subject in unique_subjects]\n",
    "# Add the legend outside the plot\n",
    "plt.legend(handles=legend_patches, title=\"Subject ID\", bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "# Adjust layout to make space for the legend\n",
    "plt.subplots_adjust(right=0.8)\n",
    "\n",
    "if save_flag:\n",
    "    print(\"saving plot...\")\n",
    "    plot_fname = f\"ROIs-{('-').join(rois)}_subjects-{('-').join(dataset_preprocessing.subjects_to_include)}_usenoiseceiling-{config['fmri']['use_noiseceiling']}_n-{n}_trialselection-{trialselection}_tsne.png\"\n",
    "    save_root = os.path.join(project_root, \"src\", \"fmriDatasetPreparation\", \"visualizations\", \"fmri_embeddings_tsne\")\n",
    "    if not os.path.exists(save_root):\n",
    "        os.makedirs(save_root)\n",
    "    plt.savefig(os.path.join(save_root, plot_fname), dpi=300)\n",
    "    #plt.show()\n",
    "    #plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_data['test_naturalistic'])\n",
    "X = np.vstack(df['fmri'].to_numpy())\n",
    "print(X.shape)\n",
    "df['X'] = X_tsne[:, 0]\n",
    "df['Y'] = X_tsne[:, 1]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df, x='X', y='Y', hue='dataset_id', palette='tab10', s=10, alpha=0.6)\n",
    "#\n",
    "plt.title('TSNE Projection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as json for viewing in webpage\n",
    "df.drop('fmri', axis=1, inplace=True)\n",
    "json_filename = f\"ROIs-{('-').join(rois)}_subjects-{('-').join(dataset_preprocessing.subjects_to_include)}_usenoiseceiling-{config['fmri']['use_noiseceiling']}_n-{n}_tsne.json\"\n",
    "save_root = os.path.join(\"/data/vision/oliva/blahner/projects/BrainEmbedder/data/tsne\")\n",
    "if not os.path.exists(save_root):\n",
    "    os.makedirs(save_root)\n",
    "df.to_json(os.path.join(project_root, \"assets\", json_filename), orient='records', lines=False)\n",
    "df.to_json(os.path.join(save_root, json_filename), orient='records', lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOSAIC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
