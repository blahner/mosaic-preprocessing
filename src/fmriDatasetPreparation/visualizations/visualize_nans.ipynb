{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize nans from all subjects in a carpet plot and flat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getenv('PYTHONPATH')) \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import hcp_utils as hcp\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "from nilearn import plotting\n",
    "import pandas as pd\n",
    "\n",
    "#local\n",
    "from src.utils.transforms import SelectROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getenv(\"DATASETS_ROOT\"), \"MOSAIC\")\n",
    "project_root = os.path.join(os.getenv(\"PROJECT_ROOT\"))\n",
    "print(f\"root: {root}\")\n",
    "print(f\"project_root: {project_root}\")\n",
    "rois = [f\"GlasserGroup_{x}\" for x in range(1,23)] #[\"GlasserGroup_1\", \"GlasserGroup_2\", \"GlasserGroup_3\",\"GlasserGroup_4\", \"GlasserGroup_5\"] #[\"LO1\",\"LO2\"] #[\"V1\"]\n",
    "ROI_selection = SelectROIs(selected_rois=rois)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indices_running = set()\n",
    "numvertices = 59412\n",
    "number_nans = defaultdict(lambda: np.zeros((numvertices,))) #keep track of how many vertices are nans for each subject\n",
    "total_responses = defaultdict(lambda: 0) #keep track of how many responses belong to each subject\n",
    "with h5py.File(os.path.join(root,'mosaic_version-1_0_0_new.hdf5'), 'r') as file:\n",
    "    print(f\"Keys: {file.keys()}\")\n",
    "    for subject_dataset in file.keys():\n",
    "        print(subject_dataset)\n",
    "        responses = file[subject_dataset]['betas'].keys()\n",
    "        for response in responses:\n",
    "            nan_indices = file[subject_dataset]['betas'][response].attrs['nan_indices']\n",
    "            total_responses[subject_dataset] += 1\n",
    "            for nidx in nan_indices:\n",
    "                number_nans[subject_dataset][nidx] += 1\n",
    "                if nidx not in nan_indices_running:\n",
    "                    nan_indices_running.add(nidx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indices_running_noiseceiling = set()\n",
    "numvertices = 59412\n",
    "number_nans_noiseceiling = defaultdict(lambda: np.zeros((numvertices,))) #keep track of how many vertices are nans for each subject\n",
    "total_responses_noiseceiling  = defaultdict(lambda: 0) #keep track of how many responses belong to each subject\n",
    "with h5py.File(os.path.join(root,'mosaic_version-1_0_0_new.hdf5'), 'r') as file:\n",
    "    print(f\"Keys: {file.keys()}\")\n",
    "    for subject_dataset in file.keys():\n",
    "        print(subject_dataset)\n",
    "        if 'noiseceilings' not in file[subject_dataset].keys():\n",
    "            continue\n",
    "        responses = file[subject_dataset]['noiseceilings'].keys()\n",
    "        for response in responses:\n",
    "            nan_indices = file[subject_dataset]['noiseceilings'][response].attrs['nan_indices']\n",
    "            total_responses_noiseceiling[subject_dataset] += 1\n",
    "            for nidx in nan_indices:\n",
    "                number_nans_noiseceiling[subject_dataset][nidx] += 1\n",
    "                if nidx not in nan_indices_running_noiseceiling:\n",
    "                    nan_indices_running_noiseceiling.add(nidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(nan_indices_running_noiseceiling).union(set(nan_indices_running))))\n",
    "for nidx in nan_indices_running_noiseceiling:\n",
    "    assert nidx in nan_indices_running #checks that no nan indices were only found in noiseceiling data but not the beta data. If this is not true, then we just have to combine the noiseceiling and beta nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the indices that were nan at least once across the whole dataset\n",
    "np.save(os.path.join(root, f\"nan_indices_dataset_new.npy\"), np.array(list(nan_indices_running)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_with_nans = defaultdict(lambda: 0)\n",
    "for idx in nan_indices_running:\n",
    "    roi = ROI_selection.index_to_roi[idx]\n",
    "    rois_with_nans[roi] += 1\n",
    "\n",
    "cols = ['ROI', 'number_nans', 'total_vertices', 'percent_nans']\n",
    "nan_data = {col: [] for col in cols}\n",
    "for k,v in rois_with_nans.items():\n",
    "    nan_data['ROI'].append(k)\n",
    "    nan_data['number_nans'].append(rois_with_nans[k])\n",
    "    nan_data['total_vertices'].append(len(ROI_selection.roi_to_index[k]))\n",
    "    nan_data['percent_nans'].append(f\"{rois_with_nans[k]/len(ROI_selection.roi_to_index[k])*100:.2f}\")\n",
    "    print(f\"ROI {k}: {rois_with_nans[k]/len(ROI_selection.roi_to_index[k])*100:.4f}% {rois_with_nans[k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df = pd.DataFrame(nan_data)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create the gray bars for total_vertices\n",
    "ax.bar(nan_df['ROI'], nan_df['total_vertices'], color='gray', label='Total Vertices')\n",
    "\n",
    "# Create the red bars for number_nans\n",
    "ax.bar(nan_df['ROI'], nan_df['number_nans'], color='red', label='Undefined Vertices')\n",
    "\n",
    "# Add percentages as text on top of the bars\n",
    "for i, row in nan_df.iterrows():\n",
    "    ax.text(\n",
    "        i, \n",
    "        row['total_vertices'] - 60,  # Position below the bar\n",
    "        f\"{row['number_nans']}\", \n",
    "        ha='center', \n",
    "        va='bottom', \n",
    "        fontsize=10, \n",
    "        color='black'\n",
    "    )\n",
    "    ax.text(\n",
    "        i, \n",
    "        row['total_vertices'] + 5,  # Position above the bar\n",
    "        f\"{row['total_vertices']}\", \n",
    "        ha='center', \n",
    "        va='bottom', \n",
    "        fontsize=10, \n",
    "        color='black'\n",
    "    )\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('ROI')\n",
    "ax.set_ylabel('Number of Vertices')\n",
    "ax.set_title('Number of Undefined Vertices and Total Vertices by ROI')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_key(item):\n",
    "    subject, dataset = item.split(\"_\")  # Split into subject and dataset\n",
    "    subject_number = int(subject.split(\"-\")[1])  # Extract the numeric part of \"sub-XX\"\n",
    "    return (dataset.lower(), subject_number)  # Return a tuple: (dataset, subject_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_nans = {k: number_nans[k]/t for k, t in total_responses.items()}\n",
    "#housekeeping\n",
    "fs = 10 #fontsize\n",
    "\n",
    "# Extract y-axis labels and values\n",
    "y_labels = list(percent_nans.keys())\n",
    "# Sort the list\n",
    "y_labels = sorted(list(percent_nans.keys()), key=sort_key)\n",
    "data_matrix = np.array([percent_nans[key] for key in y_labels])  # Rows are the keys\n",
    "\n",
    "# Create a custom colormap: white for zero, black to red for positive values\n",
    "colors = [(1, 1, 1), (0, 0, 0), (1, 0, 0)]  # RGB for white -> black -> red\n",
    "n_bins = 256\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_white_to_red\", colors, N=n_bins)\n",
    "\n",
    "# Normalize data so that 0 maps to white, and positive values start the gradient\n",
    "norm = Normalize(vmin=0, vmax=np.max(data_matrix))  # Adjust vmin and vmax as needed\n",
    "\n",
    "# Plot the heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 14))\n",
    "cax = plt.imshow(data_matrix, aspect='auto', cmap=custom_cmap, norm=norm, origin='upper')\n",
    "\n",
    "# Add x and y ticks\n",
    "plt.xticks([])\n",
    "plt.yticks(ticks=np.arange(data_matrix.shape[0]), labels=y_labels, fontsize=fs)\n",
    "\n",
    "# Define a custom colormap between two colors (e.g., white to red)\n",
    "colors = [(0.0, 0.0, 0.0), (1.0, 0.0, 0.0)]  #black to Red\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"black_red\", colors, N=256)\n",
    "\n",
    "# Add a colorbar to the axis\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.03, 0.7])  # [left, bottom, width, height]\n",
    "cbar = plt.colorbar(\n",
    "    plt.cm.ScalarMappable(cmap=custom_cmap, norm=plt.Normalize(vmin=0, vmax=1)),\n",
    "    cax=cbar_ax,\n",
    "    orientation=\"vertical\",\n",
    ")\n",
    "\n",
    "# Customize the colorbar\n",
    "cbar.set_label(\"Value\", rotation=270, labelpad=15)  # Label on the side\n",
    "cbar.set_ticks([0, 0.5, 1])  # Optional: Add ticks\n",
    "cbar.ax.set_yticklabels([\"0 (white)\", \"0.5\", \"1 (red)\"])  # Optional: Custom labels\n",
    "\n",
    "# Add axis labels\n",
    "plt.xlabel(\"Vertex\", fontsize=fs)\n",
    "plt.ylabel(\"Subject\", fontsize=fs)\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Carpet Plot\", fontsize=fs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot nans in flat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_list = ['png'] #only matters if save_flag is True \n",
    "\n",
    "save_flag=False #set to True to save plots or False to not save plots\n",
    "data_matrix_mean = data_matrix.mean(axis=0)\n",
    "print(sum(data_matrix_mean>0))\n",
    "print(data_matrix_mean.shape)\n",
    "if save_flag:\n",
    "    save_root = os.path.join(project_root, \"src\", \"output_decoding\")\n",
    "    if not os.path.exists(save_root):\n",
    "        os.makedirs(save_root)\n",
    "    filename_core = f\"nan_indices_ROIs-all_target\"\n",
    "\n",
    "views = [] #['lateral', 'medial'] #['lateral', 'medial', 'dorsal', 'ventral', 'anterior', 'posterior']\n",
    "stat = np.zeros((91282,1))\n",
    "stat[:data_matrix_mean.shape[0]] = np.reshape(data_matrix_mean, (-1,1))\n",
    "#stat = ROI_selection.sample2wb(np.reshape(results, (-1,1)),fill_value=0)\n",
    "stat = stat.squeeze() * 100\n",
    "print(stat.shape)\n",
    "for hemi in ['left','right']:\n",
    "    mesh = hcp.mesh.inflated\n",
    "    cortex_data = hcp.cortex_data(stat)\n",
    "    bg = hcp.mesh.sulc\n",
    "    for view in views:\n",
    "        display = plotting.plot_surf_roi(mesh, cortex_data, hemi=hemi,\n",
    "        threshold=1e-9, bg_map=bg, view=view, cmap='hot')\n",
    "        if save_flag:\n",
    "            for ext in ext_list:\n",
    "                if ext == 'png':\n",
    "                    plt.savefig(os.path.join(save_root, f\"{filename_core}_mesh-inflated_view-{view}_hemi-{hemi}.{ext}\"),dpi=300)\n",
    "                else:\n",
    "                    plt.savefig(os.path.join(save_root, f\"{filename_core}_mesh-inflated_view-{view}_hemi-{hemi}.{ext}\"))\n",
    "\n",
    "    #flattened brain\n",
    "    if hemi == 'left':\n",
    "        cortex_data = hcp.left_cortex_data(stat)\n",
    "        display = plotting.plot_surf_roi(hcp.mesh.flat_left, cortex_data,\n",
    "        threshold=1e-9, bg_map=hcp.mesh.sulc_left, colorbar=True, cmap='hot')\n",
    "        if save_flag:\n",
    "            for ext in ext_list:\n",
    "                if ext == 'png':\n",
    "                    plt.savefig(os.path.join(save_root, f\"{filename_core}_mesh-flat_hemi-{hemi}.{ext}\"),dpi=300)\n",
    "                else:\n",
    "                    plt.savefig(os.path.join(save_root, f\"{filename_core}_mesh-flat_hemi-{hemi}.{ext}\"))\n",
    "        plt.show()\n",
    "\n",
    "    if hemi == 'right':\n",
    "        cortex_data = hcp.right_cortex_data(stat)\n",
    "        display = plotting.plot_surf_roi(hcp.mesh.flat_right, cortex_data,\n",
    "        threshold=1e-9, bg_map=hcp.mesh.sulc_right, colorbar=True, cmap='hot')\n",
    "        if save_flag:\n",
    "            for ext in ext_list:\n",
    "                if ext == 'png':\n",
    "                    plt.savefig(os.path.join(save_root, f\"{filename_core}_mesh-flat_hemi-{hemi}.{ext}\"),dpi=300)\n",
    "                else:\n",
    "                    plt.savefig(os.path.join(save_root, f\"{filename_core}_mesh-flat_hemi-{hemi}.{ext}\"))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOSAIC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
