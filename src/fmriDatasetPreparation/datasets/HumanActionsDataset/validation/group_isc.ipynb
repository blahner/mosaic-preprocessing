{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform an intersubject correlation analysis on the categories. Each individuals betas are averaged over the 4 reps per category\n",
    "to get a series of 180 beta values per vertex. The ISC is a leave-one-out correlation between a subject and the remaining 29 subject\n",
    "group average. The final group ISC is the average of all the leave-one-out correlations. This is to replicate the results\n",
    "of the HAD manuscript Figure 6 and validate our own preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getenv('PYTHONPATH')) \n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import hcp_utils as hcp\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "\n",
    "#local\n",
    "from src.utils.helpers import vectorized_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = os.path.join(os.getenv(\"DATASETS_ROOT\", \"/default/path/to/datasets\"),\"HumanActionsDataset\") #use default if DATASETS_ROOT env variable is not set.\n",
    "project_root = os.getenv(\"PROJECT_ROOT\", \"/default/path/to/project\")\n",
    "print(f\"dataset_root: {dataset_root}\")\n",
    "print(f\"project_root: {project_root}\")\n",
    "fmri_path = os.path.join(dataset_root,\"derivatives\", \"GLM\")\n",
    "task='action'\n",
    "dataset = 'HAD'\n",
    "#first define the stimulus order and matrix.\n",
    "#Next we will essentially place the betas into this pre-defined matrix\n",
    "df = pd.read_table(os.path.join(dataset_root, \"derivatives\", \"stimuli_metadata\", \"had_stiminfo.tsv\"),index_col=False) #this stiminfo file is also saved in the MOSAIC repository\n",
    "filenames = df['filename'].tolist()\n",
    "cats = [f.split('_id_')[0].split('v_')[-1] for f in filenames]\n",
    "categories = set(cats)\n",
    "#get the order of categories\n",
    "assert(len(categories) == 180)\n",
    "subject_betas = {} #this will be a big dictionary holding all the beta estimates from the subjects\n",
    "nvertices = 91282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sub in range(1,31):\n",
    "    subject = f\"sub-{sub:02}\"\n",
    "    print(f\"loading betas for subject {subject}\")\n",
    "    #load the normalized betas for train and test\n",
    "    with open(os.path.join(fmri_path, subject, \"prepared_betas\", f\"{subject}_organized_betas_task-train_normalized.pkl\"), 'rb') as f:\n",
    "        betas_train, stimorder_train = pickle.load(f)\n",
    "    with open(os.path.join(fmri_path, subject, \"prepared_betas\", f\"{subject}_organized_betas_task-test_normalized.pkl\"), 'rb') as f:\n",
    "        betas_test, stimorder_test = pickle.load(f)\n",
    "\n",
    "    #map the stimulus to categories in order\n",
    "    categoryorder_train = []\n",
    "    for stim in stimorder_train:\n",
    "        tmp = stim.split('_id_')[0]\n",
    "        cat = tmp.split('v_')[-1]\n",
    "        categoryorder_train.append(cat)\n",
    "    categoryorder_test = []\n",
    "    for stim in stimorder_test:\n",
    "        tmp = stim.split('_id_')[0]\n",
    "        cat = tmp.split('v_')[-1]\n",
    "        categoryorder_test.append(cat)\n",
    "\n",
    "    #sort into categories\n",
    "    beta_categories = np.zeros((len(categories), nvertices))\n",
    "    for count, cat in enumerate(categories):\n",
    "        cat_idx_train = np.isin(categoryorder_train, cat)\n",
    "        cat_idx_test = np.isin(categoryorder_test, cat)\n",
    "        assert(cat_idx_train.sum() == 3)\n",
    "        assert(cat_idx_test.sum() == 1)\n",
    "\n",
    "        betas_tmp = np.concatenate((betas_train[cat_idx_train,0,:], betas_test[cat_idx_test,0, :]), axis=0)\n",
    "        assert(betas_tmp.shape[0] == 4)\n",
    "\n",
    "        beta_categories[count, :] = np.mean(betas_tmp, axis=0)\n",
    "    \n",
    "    subject_betas.update({subject: beta_categories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_vertices_list = []\n",
    "for subject, betas in subject_betas.items():\n",
    "    sub_nans = np.argwhere(np.isnan(np.mean(betas, axis=0)))\n",
    "    nan_vertices_list.extend(sub_nans.flatten())\n",
    "    print(f\"subject {subject} has {len(sub_nans)} nans\")\n",
    "nan_vertices = set(nan_vertices_list)\n",
    "print(f\"all subjects have {len(nan_vertices)} unique nans\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isc = np.zeros((nvertices,))\n",
    "subject_isc = {f\"sub-{x:02}\": 0 for x in range(1,31)}\n",
    "for left_out_subject in subject_betas.keys():\n",
    "    print(f\"running isc on left out subject: {left_out_subject}\")\n",
    "    left_out_betas = subject_betas[left_out_subject]\n",
    "\n",
    "    remaining_betas = np.zeros(left_out_betas.shape)\n",
    "    n_remainingsubs = 0\n",
    "    for key, value in subject_betas.items():\n",
    "        if key != left_out_subject:\n",
    "            n_remainingsubs += 1\n",
    "            remaining_betas += value\n",
    "    remaining_betas = remaining_betas/n_remainingsubs #average\n",
    "\n",
    "    subject_corr = vectorized_correlation(left_out_betas, remaining_betas)\n",
    "    subject_isc[left_out_subject] = subject_corr\n",
    "    isc += subject_corr\n",
    "\n",
    "isc = isc/len(subject_betas) #average the individual isc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_list = ['png'] #only matters if save_flag is True \n",
    "save_flag=True #set to True to save plots or False to not save plots\n",
    "\n",
    "save_root = os.path.join(project_root, \"src\", \"fmriDatasetPreparation\", \"datasets\", \"HumanActionsDataset\", \"validation\", \"output\", \"GroupISC\")\n",
    "if not os.path.exists(save_root):\n",
    "    os.makedirs(save_root)\n",
    "\n",
    "stat = isc.copy()\n",
    "print(f\"Min, Max Group ISC pearson correlation: {np.nanmin(stat)}, {np.nanmax(stat)}\")\n",
    "threshold = None\n",
    "cmap = 'coolwarm' #'hot'\n",
    "#save inflated surfaces\n",
    "cortex_data = hcp.cortex_data(stat)\n",
    "#determine global min/max for consistent color scaling\n",
    "datamin = np.nanmin(cortex_data)\n",
    "datamax = np.nanmax(cortex_data)\n",
    "vmin=-datamax #datamin\n",
    "vmax=datamax\n",
    "\n",
    "views = ['lateral', 'ventral', 'dorsal'] #['lateral', 'medial', 'dorsal', 'ventral', 'anterior', 'posterior']\n",
    "for hemi in ['left','right']:\n",
    "    mesh = hcp.mesh.inflated\n",
    "    bg = hcp.mesh.sulc\n",
    "    for view in views:\n",
    "        display = plotting.plot_surf_stat_map(mesh, cortex_data, hemi=hemi,\n",
    "        threshold=threshold, bg_map=bg, view=view, cmap=cmap)\n",
    "        if save_flag:\n",
    "            for ext in ext_list:\n",
    "                if ext == 'png':\n",
    "                    plt.savefig(os.path.join(save_root, f\"groupISC_{dataset}_task-{task}_mesh-inflated_view-{view}_hemi-{hemi}.{ext}\"),dpi=300)\n",
    "                else:\n",
    "                    plt.savefig(os.path.join(save_root, f\"groupISC_{dataset}_task-{task}_mesh-inflated_view-{view}_hemi-{hemi}.{ext}\"))\n",
    "\n",
    "#Save flat maps. hemispheres are combined in one plot\n",
    "#get the data for both hemispheres\n",
    "cortex_data_left = hcp.left_cortex_data(stat)\n",
    "cortex_data_right = hcp.right_cortex_data(stat)\n",
    "\n",
    "#create a figure with multiple axes to plot each anatomical image\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), subplot_kw={'projection': '3d'})\n",
    "plt.subplots_adjust(wspace=0)\n",
    "im = plotting.plot_surf(hcp.mesh.flat_left, cortex_data_left,\n",
    "        threshold=threshold, bg_map=hcp.mesh.sulc_left, \n",
    "        colorbar=False, cmap=cmap, \n",
    "        vmin=vmin, vmax=vmax,\n",
    "        axes = axes[0])\n",
    "im = plotting.plot_surf(hcp.mesh.flat_right, cortex_data_right,\n",
    "        threshold=threshold, bg_map=hcp.mesh.sulc_right, \n",
    "        colorbar=False, cmap=cmap, \n",
    "        vmin=vmin, vmax=vmax,\n",
    "        axes = axes[1])\n",
    "\n",
    "#flip along the horizontal\n",
    "axes[0].invert_yaxis()\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "#create colorbar\n",
    "norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=axes.ravel().tolist(), shrink=0.6)\n",
    "\n",
    "cbar.set_ticks([round(vmin,2), 0, round(vmax,2)])\n",
    "cbar.set_ticklabels([round(vmin,2), 0, round(vmax,2)])\n",
    "if save_flag:\n",
    "    for ext in ext_list:\n",
    "        if ext == 'png':\n",
    "            plt.savefig(os.path.join(save_root, f\"groupISC_{dataset}_task-{task}_mesh-flat.{ext}\"),dpi=300)\n",
    "        else:\n",
    "            plt.savefig(os.path.join(save_root, f\"groupISC_{dataset}_task-{task}_mesh-flat.{ext}\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot each left-out subject's correlation with the group average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_list = ['png'] #only matters if save_flag is True \n",
    "\n",
    "save_flag=True #set to True to save plots or False to not save plots\n",
    "threshold = None\n",
    "cmap = 'coolwarm' #'hot'\n",
    "save_root = os.path.join(project_root, \"src\", \"fmriDatasetPreparation\", \"datasets\", \"HumanActionsDataset\", \"validation\", \"output\", \"SubjectISC\")\n",
    "if not os.path.exists(save_root):\n",
    "    os.makedirs(save_root)\n",
    "vmin= -0.75#-1 #fix vmin and vmax for all subjects because we want to compare\n",
    "vmax=0.75 #1\n",
    "views = [] #['lateral', 'medial'] #['lateral', 'medial', 'dorsal', 'ventral', 'anterior', 'posterior']\n",
    "for left_out_subject, stat in subject_isc.items():\n",
    "    print(\"*\"*20)\n",
    "    print(f\"Min, Max subject {left_out_subject} ISC pearson correlation: {np.nanmin(stat)}, {np.nanmax(stat)}\")\n",
    "    #save inflated surfaces\n",
    "    #determine global min/max for consistent color scaling\n",
    "    cortex_data = hcp.cortex_data(stat)\n",
    "    datamin = np.nanmin(cortex_data)\n",
    "    datamax = np.nanmax(cortex_data)\n",
    "\n",
    "    views = [] #['lateral', 'medial'] #['lateral', 'medial', 'dorsal', 'ventral', 'anterior', 'posterior']\n",
    "    for hemi in ['left','right']:\n",
    "        mesh = hcp.mesh.inflated\n",
    "        bg = hcp.mesh.sulc\n",
    "        for view in views:\n",
    "            display = plotting.plot_surf_stat_map(mesh, cortex_data, hemi=hemi,\n",
    "            threshold=threshold, bg_map=bg, view=view, cmap=cmap)\n",
    "            if save_flag:\n",
    "                for ext in ext_list:\n",
    "                    if ext == 'png':\n",
    "                        plt.savefig(os.path.join(save_root, f\"{left_out_subject}_{dataset}_task-{task}_mesh-inflated_view-{view}_hemi-{hemi}_subjectISC.{ext}\"),dpi=300)\n",
    "                    else:\n",
    "                        plt.savefig(os.path.join(save_root, f\"{left_out_subject}_{dataset}_task-{task}_mesh-inflated_view-{view}_hemi-{hemi}_subjectISC.{ext}\"))\n",
    "\n",
    "    #Save flat maps. hemispheres are combined in one plot\n",
    "    #get the data for both hemispheres\n",
    "    cortex_data_left = hcp.left_cortex_data(stat)\n",
    "    cortex_data_right = hcp.right_cortex_data(stat)\n",
    "\n",
    "    #create a figure with multiple axes to plot each anatomical image\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), subplot_kw={'projection': '3d'})\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    im = plotting.plot_surf(hcp.mesh.flat_left, cortex_data_left,\n",
    "            threshold=threshold, bg_map=hcp.mesh.sulc_left, \n",
    "            colorbar=False, cmap=cmap, \n",
    "            vmin=vmin, vmax=vmax,\n",
    "            axes = axes[0])\n",
    "    im = plotting.plot_surf(hcp.mesh.flat_right, cortex_data_right,\n",
    "            threshold=threshold, bg_map=hcp.mesh.sulc_right, \n",
    "            colorbar=False, cmap=cmap, \n",
    "            vmin=vmin, vmax=vmax,\n",
    "            axes = axes[1])\n",
    "\n",
    "    #flip along the horizontal\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[1].invert_yaxis()\n",
    "\n",
    "    #create colorbar\n",
    "    norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=axes.ravel().tolist(), shrink=0.6)\n",
    "\n",
    "    cbar.set_ticks([round(vmin,2), round(datamin,2), 0, round(datamax,2), round(vmax,2)])\n",
    "    cbar.set_ticklabels([round(vmin,2), round(datamin,2), 0, round(datamax,2), round(vmax,2)])\n",
    "    if save_flag:\n",
    "        for ext in ext_list:\n",
    "            if ext == 'png':\n",
    "                plt.savefig(os.path.join(save_root, f\"{left_out_subject}_{dataset}_task-{task}_mesh-flat_subjectISC.{ext}\"),dpi=300)\n",
    "            else:\n",
    "                plt.savefig(os.path.join(save_root, f\"{left_out_subject}_{dataset}_task-{task}_mesh-flat_subjectISC.{ext}\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOSAIC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
