{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nilearn import plotting\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import hcp_utils as hcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script shows you how to reshape the fmri data into a matrix organized by conditions x repetitions x numvertices. So, indexing such a matrix like fmri_data[0,:,15000] yields all repeated instances (10 for test set, 2 for train) for the condition number 0 (find the name of the 2s clip in the associated variable 'condition_order') at voxel number 15000. This script then calculates a noiseceiling based on the variability of the data within repetitions. Be careful of interpreting this though as we are not working with beta values, but timeseries estimates. You may want to do some inter-subject and intra-subject correlations on the data too which won't be too difficult once the data is in this nice matrix format. This script also shows you how to visualize the results on an inflated and flat brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_noiseceiling(betas, n: int=1):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviation across trials, square the result,\n",
    "    average across images, and then take the square root. The result is\n",
    "    the estimate of the 'noise standard deviation'. \n",
    "    Parameters:\n",
    "    betas: beta estimates in shape (vertices, num_reps, num_stimuli)\n",
    "    Returns:\n",
    "    ncsnr: noise-ceiling SNR at each voxel in shape (voxel_x, voxel_y, voxel_z) as ratio between signal std and noise std\n",
    "    noiseceiling: noise ceiling at each voxel in shape (voxel_x, voxel_y, voxel_z) as % of explainable variance \n",
    "    Code adapted from GLMsingle example: https://github.com/cvnlab/GLMsingle/blob/main/examples/example9_noiseceiling.ipynb\n",
    "    \"\"\"\n",
    "    assert(len(betas.shape) == 3)\n",
    "    numvertices = betas.shape[0]\n",
    "    num_reps = betas.shape[1]\n",
    "    num_vids = betas.shape[2]\n",
    "    noisesd = np.sqrt(np.mean(np.power(np.std(betas,axis=1,keepdims=1,ddof=1),2),axis=2)).reshape((numvertices,))\n",
    "\n",
    "    # Calculate the total variance of the single-trial betas.\n",
    "    totalvar = np.power(np.std(np.reshape(betas, (numvertices , num_reps*num_vids)), axis=1),2)\n",
    "\n",
    "    # Estimate the signal variance and positively rectify.\n",
    "    signalvar = totalvar - np.power(noisesd,2)\n",
    "\n",
    "    signalvar[signalvar < 0] = 0\n",
    "    # Compute ncsnr as the ratio between signal standard deviation and noise standard deviation.\n",
    "    ncsnr = np.sqrt(signalvar) / noisesd\n",
    "\n",
    "    # Compute noise ceiling in units of percentage of explainable variance\n",
    "    noiseceiling = 100 * (np.power(ncsnr,2) / (np.power(ncsnr,2) + 1/n))\n",
    "    return ncsnr, noiseceiling\n",
    "\n",
    "def list_rep(myList: list, reps: int):\n",
    "    #returns a list of items in \"mylist\" that are repeated \"reps\" number of times\n",
    "    repList = []\n",
    "    # traverse for all elements\n",
    "    for x in myList:\n",
    "        if x not in repList: \n",
    "            count = myList.count(x)\n",
    "            if count == reps:\n",
    "                repList.append(x)\n",
    "    return repList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup paths and housekeeping\n",
    "dataset_root = os.path.join(os.getenv(\"DATASETS_ROOT\", \"/default/path/to/datasets\"),\"CC2017\") #use default if DATASETS_ROOT env variable is not set.\n",
    "project_root = os.getenv(\"PROJECT_ROOT\", \"/default/path/to/datasets\")\n",
    "\n",
    "print(f\"dataset_root: {dataset_root}\")\n",
    "\n",
    "fmri_path = os.path.join(dataset_root,\"video_fmri_dataset\")\n",
    "nvertices = 91282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define subject and session\n",
    "n_task = {'train': [1,2], 'test': [1,10]}\n",
    "ext_list = ['eps','png']\n",
    "save_flag = False\n",
    "for subject in range(1,4):\n",
    "    save_root = os.path.join(project_root, \"src\", \"fmriDatasetPreparation\", \"datasets\", \"CC2017\", \"validation\", \"output\", \"noiseceiling\", f\"subject{subject}\")\n",
    "    if not os.path.exists(save_root) and save_flag:\n",
    "        os.makedirs(save_root)\n",
    "\n",
    "    for task in ['test','train']:#load ts estimates\n",
    "        with open(os.path.join(fmri_path, \"TSTrialEstimates\", f\"subject{subject}\", \"estimates-prepared\", \"step01\", f\"subject{subject}_z=1_TSTrialEstimates_task-{task}.pkl\"), 'rb') as f:\n",
    "            estimates, condition_order = pickle.load(f) #shape nvideos, nvertices \n",
    "        #reshape the trial estimates into a matrix organized by condition and its repeates\n",
    "        numreps = max(n_task[task])\n",
    "        repeated_conditions = list_rep(condition_order, numreps) #just get the conditions repeated exactly numpreps times (10 for test, 2 for train)\n",
    "        fmri = np.zeros((len(repeated_conditions), numreps, nvertices))\n",
    "        for cond_idx, cond in tqdm(enumerate(repeated_conditions), total=len(repeated_conditions), desc=f\"Reorganizing data into condition x repeats x vertices matrix\"):\n",
    "            indices = [i for i, x in enumerate(condition_order) if x == cond]\n",
    "            fmri[cond_idx, :, :] = estimates[np.array(indices).astype(int), :]\n",
    "\n",
    "        fmri = fmri.T\n",
    "        print(f\"shape of fmri data in vertices x repeats x conditions matrix: {fmri.shape}\")\n",
    "        for n in n_task[task]:\n",
    "            print(\"calculating noiseceiling...\")\n",
    "            ncsnr, noiseceiling = calculate_noiseceiling(fmri, n=n)\n",
    "            print(f\"subject{subject} {task} n={n} max noiseceiling: {np.nanmax(noiseceiling)}\")\n",
    "            \n",
    "            views = ['lateral', 'medial'] #['lateral', 'medial', 'dorsal', 'ventral', 'anterior', 'posterior']\n",
    "            noiseceiling[noiseceiling < 0] = 0\n",
    "            stat = noiseceiling.copy()\n",
    "            for hemi in ['left','right']:\n",
    "                mesh = hcp.mesh.inflated\n",
    "                cortex_data = hcp.cortex_data(stat)\n",
    "                bg = hcp.mesh.sulc\n",
    "                for view in views:\n",
    "                    display = plotting.plot_surf_stat_map(mesh, cortex_data, hemi=hemi,\n",
    "                    threshold=1, bg_map=bg, view=view, cmap='hot')\n",
    "                    if save_flag:\n",
    "                        for ext in ext_list:\n",
    "                            if ext == 'png':\n",
    "                                plt.savefig(os.path.join(save_root, f\"subject{subject}_task-{task}_mesh-inflated_view-{view}_hemi-{hemi}_n-{n}_trialestimates.{ext}\"),dpi=300)\n",
    "                            else:\n",
    "                                plt.savefig(os.path.join(save_root, f\"sub-{subject:02}_task-{task}_mesh-inflated_view-{view}_hemi-{hemi}_n-{n}_trialestimates.{ext}\"))\n",
    "\n",
    "                #flattened brain\n",
    "                if hemi == 'left':\n",
    "                    cortex_data = hcp.left_cortex_data(stat)\n",
    "                    display = plotting.plot_surf(hcp.mesh.flat_left, cortex_data,\n",
    "                    threshold=1, bg_map=hcp.mesh.sulc_left, colorbar=True, cmap='hot')\n",
    "                    if save_flag:\n",
    "                        for ext in ext_list:\n",
    "                            if ext == 'png':\n",
    "                                plt.savefig(os.path.join(save_root, f\"sub-{subject:02}_task-{task}_mesh-flat_hemi-{hemi}_n-{n}_trialestimates.{ext}\"),dpi=300)\n",
    "                            else:\n",
    "                                plt.savefig(os.path.join(save_root, f\"sub-{subject:02}_task-{task}_mesh-flat_hemi-{hemi}_n-{n}_trialestimates.{ext}\"))\n",
    "                    plt.show()\n",
    "\n",
    "                if hemi == 'right':\n",
    "                    cortex_data = hcp.right_cortex_data(stat)\n",
    "                    display = plotting.plot_surf(hcp.mesh.flat_right, cortex_data,\n",
    "                    threshold=1, bg_map=hcp.mesh.sulc_right, colorbar=True, cmap='hot')\n",
    "                    if save_flag:\n",
    "                        for ext in ext_list:\n",
    "                            if ext == 'png':\n",
    "                                plt.savefig(os.path.join(save_root, f\"sub-{subject:02}_task-{task}_mesh-flat_hemi-{hemi}_n-{n}_trialestimates.{ext}\"),dpi=300)\n",
    "                            else:\n",
    "                                plt.savefig(os.path.join(save_root, f\"sub-{subject:02}_task-{task}_mesh-flat_hemi-{hemi}_n-{n}_trialestimates.{ext}\"))\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuroAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
